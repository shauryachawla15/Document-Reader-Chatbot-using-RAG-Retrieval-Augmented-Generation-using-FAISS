# Document-Reader-Chatbot-using-RAG-Retrieval-Augmented-Generation-using-FAISS
A **Retrieval-Augmented Generation (RAG)** based chatbot that allows users to ask natural language questions from PDF documents.  
The system retrieves relevant document context using vector similarity search and generates accurate, grounded answers using an LLM.

---

## ğŸ§  Project Overview

This project implements a **RAG-based document question answering system** using:
- Local embedding models (Sentence Transformers)
- Vector similarity search (FAISS)
- OpenAI language models for response generation

Instead of relying on the LLMâ€™s internal knowledge, the chatbot retrieves the most relevant parts of the document and answers **strictly based on the document content**, minimizing hallucinations.

---

## ğŸš€ Features

- ğŸ“„ PDF text extraction
- âœ‚ï¸ Document chunking
- ğŸ§  Semantic embeddings (local & free)
- ğŸ” FAISS vector search
- ğŸ¤– LLM-based answer generation
- ğŸ›¡ï¸ Context-restricted answers (RAG)
- ğŸŒ Flask web interface
- âš¡ Fast and lightweight

---

## ğŸ—ï¸ Architecture (How It Works)

1. Load and extract text from a PDF
2. Split text into fixed-size chunks
3. Convert chunks into embeddings
4. Store embeddings in a FAISS index
5. Embed user question
6. Retrieve the most relevant chunk
7. Generate answer using the retrieved context

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|--------|-----------|
| Backend | Flask |
| Embeddings | Sentence-Transformers (`all-MiniLM-L6-v2`) |
| Vector Database | FAISS |
| LLM | OpenAI (`gpt-4o-mini`) |
| PDF Parsing | PyPDF |
| Frontend | HTML, CSS |
| Language | Python |

---

## ğŸ“‚ Project Structure

```text
doc-reader-chatbot/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample.pdf
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html
â”œâ”€â”€ static/
â”‚   â””â”€â”€ style.css
â””â”€â”€ README.md



